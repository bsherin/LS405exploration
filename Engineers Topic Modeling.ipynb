{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling with NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF (Non-negative Matrix Factorization) \n",
    "\n",
    "We are going to start with one algorithm that can be used for topic modeling NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the imports we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# This is the new one\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_id_segmented = \"1ukY3sWTM3v26100ZYchGr66HPN8JI0UB-\"\n",
    "# url = f'https://drive.google.com/uc?id={file_id_segmented}'\n",
    "url = \"corpora/engineer_df_segmented.parquet\"\n",
    "\n",
    "corpus_df = pd.read_parquet(url)\n",
    "corpus_df.rename(columns={\"text\": \"Document\"}, inplace=True)\n",
    "corpus_df.drop(columns=[\"tokenized\", \"doc\"], inplace=True)\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters we might want to vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list_source = \"engineer_stop_list.txt\"\n",
    "vocabulary_size = 100\n",
    "n_topics = 10\n",
    "norm = False\n",
    "max_ngram = 1\n",
    "# Vectorizer = TfidfVectorizer\n",
    "Vectorizer = CountVectorizer\n",
    "\n",
    "extra_stop_words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the document x term matrix\n",
    "\n",
    "We are also going to create a frequency distribution for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stop_list_source == \"english\":\n",
    "    stopwords = \"english\"\n",
    "else:\n",
    "    with open('lists/' + stop_list_source, 'r') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    stopwords += extra_stop_words\n",
    "\n",
    "vectorizer = Vectorizer(max_features=vocabulary_size, \n",
    "                        stop_words=stopwords, \n",
    "                        ngram_range=(1, max_ngram))\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(corpus_df['Document'].values)\n",
    "if norm:\n",
    "    doc_term_matrix = normalize(X, norm='l2')\n",
    "corpus_df[\"vector\"] = [x for x in doc_term_matrix.toarray()]\n",
    "\n",
    "word_counts = np.array(doc_term_matrix.sum(axis=0)).flatten()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "fdist = dict(zip(feature_names, word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(init=\"nndsvd\", n_components=n_topics) \n",
    "doc_topic_matrix = nmf_model.fit_transform(doc_term_matrix)\n",
    "topic_term_matrix = nmf_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_val = .7\n",
    "\n",
    "topic_rel_dfs = display_topics(nmf_model, vectorizer, fdist, lambda_val, 10, True)\n",
    "\n",
    "topic_labels = []\n",
    "for topic_df in topic_rel_dfs:\n",
    "    words = topic_df[\"word\"].tolist()[:2]\n",
    "    label = words[0] + \"-\" + words[1]\n",
    "    topic_labels.append(label)\n",
    "topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.DataFrame(doc_topic_matrix, columns=topic_labels)\n",
    "corpus_df = corpus_df.reset_index(drop=True)\n",
    "topic_df = topic_df.reset_index(drop=True)\n",
    "corpus_df = pd.concat([corpus_df, topic_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_label = \"engineering-design\"\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "top_10 = corpus_df.sort_values(by=topic_labels, ascending=False).head(10)\n",
    "top_10.drop(columns=[\"vector\"], inplace=True)\n",
    "\n",
    "# Assuming top_10_rows is your DataFrame containing the top 10 rows\n",
    "for index, row in top_10.iterrows():\n",
    "    document = row['Document']  # Assuming 'Document' is the column name\n",
    "    display(HTML(f\"<div style='border: 1px solid #ccc; padding: 10px; margin: 10px;'><strong>Document {index + 1}:</strong><br>{document}</div>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls405_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
