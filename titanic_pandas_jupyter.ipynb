{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn1GyYbPW5pY"
      },
      "source": [
        "<table>\n",
        "<tbody>\n",
        "<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n",
        "<tr>\n",
        "<td>survival</td>\n",
        "<td>Survival</td>\n",
        "<td>0 = No, 1 = Yes</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pclass</td>\n",
        "<td>Ticket class</td>\n",
        "<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>sex</td>\n",
        "<td>Sex</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Age</td>\n",
        "<td>Age in years</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>sibsp</td>\n",
        "<td># of siblings / spouses aboard the Titanic</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>parch</td>\n",
        "<td># of parents / children aboard the Titanic</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>ticket</td>\n",
        "<td>Ticket number</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>fare</td>\n",
        "<td>Passenger fare</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>cabin</td>\n",
        "<td>Cabin number</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>embarked</td>\n",
        "<td>Port of Embarkation</td>\n",
        "<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCKO3193W5pY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bsherin/LS405exploration\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "%cd LS405exploration\n",
        "from utilities import *\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# file_id = \"1lXO7JEO99fLidhHJDdZUpxinXTiU8Vf-\"\n",
        "# url = f'https://drive.google.com/uc?id={file_id}'\n",
        "url = 'corpora/titanic.csv'\n",
        "df = pd.read_csv(url)\n",
        "dlist = df.to_dict('records')"
      ],
      "metadata": {
        "id": "mm94qWTaXFYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcHX7NrgW5pZ"
      },
      "source": [
        "# Frequency Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bszj5X0W5pZ"
      },
      "outputs": [],
      "source": [
        "def fix_numbers(df, col):\n",
        "    df_fixed = df[df[col] != \"\"]\n",
        "    df_fixed = df_fixed.astype({col: \"float\"})\n",
        "    return df_fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lpf_jqVW5pZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def freq_plot(df, col, by, nbins=10):\n",
        "    df_fixed = fix_numbers(df, col)\n",
        "    the_max = df_fixed[col].max()\n",
        "    the_min = df_fixed[col].min()\n",
        "    w = int((the_max - the_min) / nbins)\n",
        "    bins = [int(w * c) for c in range(nbins + 1)]\n",
        "    df_fixed.hist(column=col, by=by, bins=bins)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00WK9UaEW5pZ"
      },
      "outputs": [],
      "source": [
        "freq_plot(df, \"Age\", \"Pclass\", 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJaz-UtgW5pZ"
      },
      "outputs": [],
      "source": [
        "df_age = fix_numbers(df, \"Age\")\n",
        "df_age[df_age[\"Pclass\"] == 1][\"Age\"].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K9QOR6BW5pZ"
      },
      "outputs": [],
      "source": [
        "df_age[df_age[\"Pclass\"] == 2][\"Age\"].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQks-LtTW5pZ"
      },
      "outputs": [],
      "source": [
        "df_age[df_age[\"Pclass\"] == 3][\"Age\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a56sDPXWW5pZ"
      },
      "source": [
        "# Contingency Table and chi_squared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTXP1a8yW5pZ"
      },
      "outputs": [],
      "source": [
        "def build_ftable(df, row_param, col_param):\n",
        "    rlabels = sorted(df[row_param].unique())\n",
        "    clabels = sorted(df[col_param].unique())\n",
        "    the_table = [[\"\"] + list(clabels)]\n",
        "    core_table = []\n",
        "    for rl in rlabels:\n",
        "        the_row = [rl]\n",
        "        core_row = []\n",
        "        dfr = df[df[row_param] == rl]\n",
        "        for cl in clabels:\n",
        "            the_row.append(len(dfr[dfr[col_param] == cl]))\n",
        "            core_row.append(len(dfr[dfr[col_param] == cl]))\n",
        "        the_table.append(the_row)\n",
        "        core_table.append(core_row)\n",
        "    title = f\"rows={row_param}, cols={col_param}\"\n",
        "    the_html = html_table(the_table, title=title)\n",
        "    display(the_html)\n",
        "    return core_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZUSsCmHW5pZ"
      },
      "outputs": [],
      "source": [
        "res_table = build_ftable(df, \"Pclass\", \"Survived\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXJQUDVkW5pZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rtt = np.array(res_table).transpose()\n",
        "rtt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILrqs4OKW5pZ"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "def surv_chi(df, row_param):\n",
        "    core_table = build_ftable(df, row_param, \"Survived\")\n",
        "    stat, p, dof, expected = chi2_contingency(core_table)\n",
        "    return stat, p, dof, expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGN1yIocW5pZ"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "def surv_chi_t(df, row_param):\n",
        "    core_table = build_ftable(df, row_param, \"Survived\")\n",
        "    ctt = np.array(core_table).transpose()\n",
        "    display(html_table(ctt))\n",
        "    stat, p, dof, expected = chi2_contingency(ctt)\n",
        "    return stat, p, dof, expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU8QnZmpW5pZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "stat, p, dof, expected = surv_chi(df, \"Pclass\")\n",
        "print(f\"Stat: {stat}\")\n",
        "print(f\"p: {p}\")\n",
        "print(f\"dof: {dof}\")\n",
        "print(f\"expected: {np.round(expected)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCZaEdHeW5pa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "stat, p, dof, expected = surv_chi_t(df, \"Pclass\")\n",
        "print(f\"Stat: {stat}\")\n",
        "print(f\"p: {p}\")\n",
        "print(f\"dof: {dof}\")\n",
        "print(f\"expected: {np.round(expected)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj53Zq9sW5pa"
      },
      "source": [
        "# t-test and anova"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF7VYv-NW5pa"
      },
      "outputs": [],
      "source": [
        "freq_plot(df, \"Age\", \"Survived\", 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbERl_bPW5pa"
      },
      "outputs": [],
      "source": [
        "for surv in [\"0\", \"1\"]:\n",
        "    print(df_age[df_age[\"Survived\"] == surv][\"Age\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbp0GGz6W5pa"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3JEvKo_W5pa"
      },
      "outputs": [],
      "source": [
        "ttest_ind(df_age[df_age[\"Survived\"] == \"0\"][\"Age\"], df_age[df_age[\"Survived\"] == \"1\"][\"Age\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHGuBW_4W5pa"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind, f_oneway\n",
        "dsets = None\n",
        "def surv_test(df, row, col):\n",
        "    rnames = list(df[row].unique())\n",
        "    dsets = [df[df[row] == r][col] for r in rnames]\n",
        "    if len(rnames) == 2:\n",
        "        res = ttest_ind(*dsets)\n",
        "    else:\n",
        "        res = f_oneway(*dsets)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkYoiczFW5pa"
      },
      "outputs": [],
      "source": [
        "surv_test(df_age, \"Survived\", \"Age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZbKYAVhW5pa"
      },
      "outputs": [],
      "source": [
        "surv_test(df_age, \"Pclass\", \"Age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdsGj7N-W5pa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Assuming your DataFrame is named `df` and has the relevant columns\n",
        "\n",
        "# Step 1: Handle missing data in the 'Age' column\n",
        "dfn = df_age.dropna(subset=['Age', 'Survived'])\n",
        "\n",
        "# Step 2: Perform one-way ANOVA to compare the mean age of survivors and non-survivors\n",
        "survived = dfn[dfn['Survived'] == 1]['Age']\n",
        "not_survived = dfn[dfn['Survived'] == 0]['Age']\n",
        "\n",
        "# Step 3: Perform ANOVA using scipy\n",
        "res = stats.f_oneway(survived, not_survived)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VthyoN2hW5pa"
      },
      "outputs": [],
      "source": [
        "res.statistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OW64jU1W5pa"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Step 1: Handle missing data (if any) in Age, Pclass, and Survived\n",
        "dfn = df_age.dropna(subset=['Age', 'Pclass', 'Survived'])\n",
        "\n",
        "# Step 2: Create an interaction term between Pclass and Survived\n",
        "# We treat Survived as a factor even though it is binary\n",
        "model = ols('Age ~ C(Pclass) * C(Survived)', data=dfn).fit()\n",
        "\n",
        "# Step 3: Perform the two-way ANOVA\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Step 4: View the ANOVA table\n",
        "display(html_table(anova_table))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-8eTdfaW5pa"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FztVBOX6W5pa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.spatial.distance import pdist, squareform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YgDTBr3W5pa"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Survived', 'Pclass', \"Sex\", \"Embarked\"]\n",
        "numerical_cols = [\"Fare\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRULuEWgW5pa"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_categorical = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_data = pd.concat([pd.DataFrame(encoded_categorical), df[numerical_cols].reset_index(drop=True)], axis=1)\n",
        "hamming_distance_matrix = pdist(encoded_categorical, metric='hamming')\n",
        "hamming_distance_matrix = MinMaxScaler().fit_transform(squareform(hamming_distance_matrix))\n",
        "df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
        "numerical_distance_matrix = pdist(df[numerical_cols], metric='euclidean')\n",
        "numerical_distance_matrix = MinMaxScaler().fit_transform(squareform(numerical_distance_matrix))\n",
        "combined_distance_matrix = 0.9 * hamming_distance_matrix + 0.1 * numerical_distance_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPNEbJUVW5pa"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Perform hierarchical clustering using the precomputed distance matrix\n",
        "clustering = AgglomerativeClustering(n_clusters=3, metric='precomputed', linkage='complete')\n",
        "\n",
        "# Fit the clustering model to the combined distance matrix\n",
        "cluster_labels = clustering.fit_predict(squareform(combined_distance_matrix))\n",
        "\n",
        "# Add the cluster labels back to the original dataframe\n",
        "df['cluster'] = cluster_labels\n",
        "\n",
        "# Show the dataframe with clusters\n",
        "display(html_table(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvulOQb4W5pa"
      },
      "outputs": [],
      "source": [
        "df[\"cluster\"].value_counts().to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JooxU5uSW5pa"
      },
      "outputs": [],
      "source": [
        "df = Collection[\"titanic\"].df\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_categorical = encoder.fit_transform(df[categorical_cols])\n",
        "\n",
        "# Compute Hamming distance for the categorical data\n",
        "hamming_distance_matrix = pdist(encoded_categorical, metric='hamming')\n",
        "\n",
        "# Compute Euclidean distance for the numerical data\n",
        "df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
        "numerical_distance_matrix = pdist(df[numerical_cols], metric='euclidean')\n",
        "\n",
        "# Normalize the condensed distance matrices (1D form)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Reshape to 2D so that the scaler can be applied (scalers need 2D input)\n",
        "hamming_distance_matrix_reshaped = hamming_distance_matrix.reshape(-1, 1)\n",
        "numerical_distance_matrix_reshaped = numerical_distance_matrix.reshape(-1, 1)\n",
        "\n",
        "# Fit the scaler on both distance matrices and transform\n",
        "hamming_distance_matrix_normalized = scaler.fit_transform(hamming_distance_matrix_reshaped).flatten()\n",
        "numerical_distance_matrix_normalized = scaler.fit_transform(numerical_distance_matrix_reshaped).flatten()\n",
        "\n",
        "# Combine the normalized distance matrices (adjust the weights as needed)\n",
        "combined_distance_matrix = 0.9 * hamming_distance_matrix_normalized + 0.1 * numerical_distance_matrix_normalized\n",
        "\n",
        "# Convert the combined distance matrix back into a symmetric square form\n",
        "combined_distance_matrix_square = squareform(combined_distance_matrix)\n",
        "\n",
        "# Check if the distance matrix is symmetric\n",
        "assert (combined_distance_matrix_square == combined_distance_matrix_square.T).all(), \"Matrix is not symmetric\"\n",
        "\n",
        "# Now use this combined matrix for clustering\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Perform hierarchical clustering using the combined precomputed distance matrix\n",
        "clustering = AgglomerativeClustering(n_clusters=3, metric='precomputed', linkage='complete')\n",
        "cluster_labels = clustering.fit_predict(combined_distance_matrix_square)\n",
        "\n",
        "# Add the cluster labels back to the original dataframe\n",
        "df['cluster'] = cluster_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeJFl-EcW5pa"
      },
      "outputs": [],
      "source": [
        "df[\"cluster\"].value_counts().to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgA77ozGW5pa"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.clf()\n",
        "# Combine numerical and encoded categorical data\n",
        "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "combined_data = pd.concat([encoded_categorical_df, df[numerical_cols].reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Perform t-SNE to reduce the combined data to 2 dimensions\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "reduced_tsne = tsne.fit_transform(combined_data)\n",
        "\n",
        "# Plot the clusters\n",
        "plt.scatter(reduced_tsne[:, 0], reduced_tsne[:, 1], c=df['cluster'], cmap='plasma')\n",
        "plt.title('Cluster Visualization with t-SNE')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "# plt.colorbar(label='Cluster')\n",
        "self.create_pyplot_html()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuQBmBErW5pa"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Perform linkage for hierarchical clustering\n",
        "Z = linkage(squareform(combined_distance_matrix), method='complete')\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.clf()\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(Z)\n",
        "plt.title('Dendrogram for Hierarchical Clustering')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "self.create_pyplot_html()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvmQ3YswW5pe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}